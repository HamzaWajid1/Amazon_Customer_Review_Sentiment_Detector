{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Tii_N_vnnEh4lzKlGPOifUt0SXBsRWj-",
      "authorship_tag": "ABX9TyMpJK6Gehz6+B80kUlc3Qta",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamzaWajid1/Amazon_Customer_Review_Sentiment_Detector/blob/master/Training_Bert_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SENTIMENT ANALYSIS USING THE POWER OF NLP**\n",
        "\n",
        "\n",
        "In this notebooke I will be doing sentiment analysis using following techniques\n",
        "\n",
        "1: Bag of word approach\n",
        "\n",
        "2: Roberta pretrained Model\n",
        "\n",
        "3: Huggingface Pipeline"
      ],
      "metadata": {
        "id": "iz-g4pQ6Xhnw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**READING DATA**"
      ],
      "metadata": {
        "id": "EnDjMTYvYMeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roberta Pretrained Model\n",
        "\n",
        "Use a model trained of a large corpus of data.\n",
        "\n",
        "Transformer model accounts for the words but also the context related to other words."
      ],
      "metadata": {
        "id": "VZ7mrmeMBIVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "e7VEh4pFDpgo"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "lfvY3MrIXd4b"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig"
      ],
      "metadata": {
        "id": "OAPsr5UuqWUl"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "2vfKLqBnsmTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c15402-e8e3-4ceb-8862-3a69c849ce5e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/CSV Files/file.csv\")"
      ],
      "metadata": {
        "id": "GnHyS7PGDljI"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "tme5aJYKFJfV",
        "outputId": "da737579-6eea-4a6a-fb74-c77109895cfc"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  neg    neu    pos  compound   ProductId          UserId ProfileName  \\\n",
              "0   1  0.0  0.695  0.305    0.9441  B001E4KFG0  A3SGXH7AUHU8GW  delmartian   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "\n",
              "                 Summary                                               Text  \n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ad2d4fe-f2ae-41ea-b006-ffeb353acdea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>compound</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.695</td>\n",
              "      <td>0.305</td>\n",
              "      <td>0.9441</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ad2d4fe-f2ae-41ea-b006-ffeb353acdea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ad2d4fe-f2ae-41ea-b006-ffeb353acdea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ad2d4fe-f2ae-41ea-b006-ffeb353acdea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "id": "PvIpUu8onHBd",
        "outputId": "0acbed5a-bcd8-4dea-dcb9-9a0e45e345d2"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Id    neg    neu    pos  compound   ProductId          UserId  \\\n",
              "0          1  0.000  0.695  0.305    0.9441  B001E4KFG0  A3SGXH7AUHU8GW   \n",
              "1          2  0.138  0.862  0.000   -0.5664  B00813GRG4  A1D87F6ZCVE5NK   \n",
              "2          3  0.091  0.754  0.155    0.8265  B000LQOCH0   ABXLMWJIXXAIN   \n",
              "3          4  0.000  1.000  0.000    0.0000  B000UA0QIQ  A395BORC6FGVXV   \n",
              "4          5  0.000  0.552  0.448    0.9468  B006K2ZZ7K  A1UQRSCLF8GW1T   \n",
              "...      ...    ...    ...    ...       ...         ...             ...   \n",
              "19995  19996  0.043  0.830  0.127    0.6374  B002C50X1M  A1XRXZI5KOMVDD   \n",
              "19996  19997  0.048  0.783  0.169    0.7567  B002C50X1M   A7G9M0IE7LABX   \n",
              "19997  19998  0.000  0.863  0.137    0.9382  B002C50X1M  A38J5PRUDESMZF   \n",
              "19998  19999  0.038  0.722  0.240    0.9688  B002C50X1M  A17TPOSAG43GSM   \n",
              "19999  20000  0.021  0.854  0.124    0.8908  B002C50X1M  A3LWC833HQIG7J   \n",
              "\n",
              "                           ProfileName  HelpfulnessNumerator  \\\n",
              "0                           delmartian                     1   \n",
              "1                               dll pa                     0   \n",
              "2      Natalia Corres \"Natalia Corres\"                     1   \n",
              "3                                 Karl                     3   \n",
              "4        Michael D. Bigham \"M. Wassir\"                     0   \n",
              "...                                ...                   ...   \n",
              "19995            KAF1958 \"amandaf0626\"                     0   \n",
              "19996                            Kevin                     0   \n",
              "19997                              ray                     0   \n",
              "19998                          Herrick                     0   \n",
              "19999                     austin_Larry                     0   \n",
              "\n",
              "       HelpfulnessDenominator  Score        Time  \\\n",
              "0                           1      5  1303862400   \n",
              "1                           0      1  1346976000   \n",
              "2                           1      4  1219017600   \n",
              "3                           3      2  1307923200   \n",
              "4                           0      5  1350777600   \n",
              "...                       ...    ...         ...   \n",
              "19995                       0      4  1307664000   \n",
              "19996                       0      5  1307059200   \n",
              "19997                       0      5  1305763200   \n",
              "19998                       0      3  1303171200   \n",
              "19999                       0      5  1295568000   \n",
              "\n",
              "                                                 Summary  \\\n",
              "0                                  Good Quality Dog Food   \n",
              "1                                      Not as Advertised   \n",
              "2                                  \"Delight\" says it all   \n",
              "3                                         Cough Medicine   \n",
              "4                                            Great taffy   \n",
              "...                                                  ...   \n",
              "19995                                    Crispy and tart   \n",
              "19996  Exceeded my expectations. One of the best chip...   \n",
              "19997  Awesome Goodness! (deep river kettle chips, sw...   \n",
              "19998       Pretty good, but prefer other jalapeno chips   \n",
              "19999  Excellent chips, full of flavor and just the r...   \n",
              "\n",
              "                                                    Text  \n",
              "0      I have bought several of the Vitality canned d...  \n",
              "1      Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2      This is a confection that has been around a fe...  \n",
              "3      If you are looking for the secret ingredient i...  \n",
              "4      Great taffy at a great price.  There was a wid...  \n",
              "...                                                  ...  \n",
              "19995  Deep River Salt & Vinegar chips are thick and ...  \n",
              "19996  I was very skeptical about buying a brand of c...  \n",
              "19997  Before you turn to other name brands out there...  \n",
              "19998  I was expecting some \"serious flavor\" as it wa...  \n",
              "19999  I purchased the Salt and Vinegar chips and hav...  \n",
              "\n",
              "[20000 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3564554b-ada6-4adb-986f-7a86fbf22159\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>compound</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.695</td>\n",
              "      <td>0.305</td>\n",
              "      <td>0.9441</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.862</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.5664</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.091</td>\n",
              "      <td>0.754</td>\n",
              "      <td>0.155</td>\n",
              "      <td>0.8265</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.552</td>\n",
              "      <td>0.448</td>\n",
              "      <td>0.9468</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>19996</td>\n",
              "      <td>0.043</td>\n",
              "      <td>0.830</td>\n",
              "      <td>0.127</td>\n",
              "      <td>0.6374</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A1XRXZI5KOMVDD</td>\n",
              "      <td>KAF1958 \"amandaf0626\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1307664000</td>\n",
              "      <td>Crispy and tart</td>\n",
              "      <td>Deep River Salt &amp; Vinegar chips are thick and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>19997</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.783</td>\n",
              "      <td>0.169</td>\n",
              "      <td>0.7567</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A7G9M0IE7LABX</td>\n",
              "      <td>Kevin</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1307059200</td>\n",
              "      <td>Exceeded my expectations. One of the best chip...</td>\n",
              "      <td>I was very skeptical about buying a brand of c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>19998</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.863</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.9382</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A38J5PRUDESMZF</td>\n",
              "      <td>ray</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1305763200</td>\n",
              "      <td>Awesome Goodness! (deep river kettle chips, sw...</td>\n",
              "      <td>Before you turn to other name brands out there...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>19999</td>\n",
              "      <td>0.038</td>\n",
              "      <td>0.722</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.9688</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A17TPOSAG43GSM</td>\n",
              "      <td>Herrick</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1303171200</td>\n",
              "      <td>Pretty good, but prefer other jalapeno chips</td>\n",
              "      <td>I was expecting some \"serious flavor\" as it wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>20000</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.124</td>\n",
              "      <td>0.8908</td>\n",
              "      <td>B002C50X1M</td>\n",
              "      <td>A3LWC833HQIG7J</td>\n",
              "      <td>austin_Larry</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1295568000</td>\n",
              "      <td>Excellent chips, full of flavor and just the r...</td>\n",
              "      <td>I purchased the Salt and Vinegar chips and hav...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3564554b-ada6-4adb-986f-7a86fbf22159')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3564554b-ada6-4adb-986f-7a86fbf22159 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3564554b-ada6-4adb-986f-7a86fbf22159');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0bae71d2-b3da-4b46-94e5-e7d5fa49abe8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0bae71d2-b3da-4b46-94e5-e7d5fa49abe8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0bae71d2-b3da-4b46-94e5-e7d5fa49abe8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_68cbb81e-2fd4-4e2c-82e1-9f6e522ac155\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_68cbb81e-2fd4-4e2c-82e1-9f6e522ac155 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "Y=df['Score'].values.reshape(-1,1)\n",
        "One_hot = encoder.fit_transform(Y)\n",
        "One_hot=One_hot.tolist()\n",
        "One_hot = [[int(element) for element in sub_list] for sub_list in One_hot]\n",
        "One_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PdK0TIGnQl-",
        "outputId": "84a022eb-cac8-4edf-ebd1-570c7f0eac00"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 1, 0],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [0, 0, 0, 0, 1],\n",
              " [1, 0, 0, 0, 0],\n",
              " [0, 1, 0, 0, 0],\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['One']=One_hot"
      ],
      "metadata": {
        "id": "rMvn3Reonl54"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df[['Text', 'One']].copy()\n",
        "new_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8TQvWxJYpO4A",
        "outputId": "4b0c90ed-189b-4a36-b53e-482beb430a24"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text              One\n",
              "0  I have bought several of the Vitality canned d...  [0, 0, 0, 0, 1]\n",
              "1  Product arrived labeled as Jumbo Salted Peanut...  [1, 0, 0, 0, 0]\n",
              "2  This is a confection that has been around a fe...  [0, 0, 0, 1, 0]\n",
              "3  If you are looking for the secret ingredient i...  [0, 1, 0, 0, 0]\n",
              "4  Great taffy at a great price.  There was a wid...  [0, 0, 0, 0, 1]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17b8815a-271b-4c59-9ca6-3b57fc1d03e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>One</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>[0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>[1, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>[0, 0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>[0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>[0, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17b8815a-271b-4c59-9ca6-3b57fc1d03e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17b8815a-271b-4c59-9ca6-3b57fc1d03e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17b8815a-271b-4c59-9ca6-3b57fc1d03e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f75457c-6f03-4e59-886d-c9b99e98f88f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f75457c-6f03-4e59-886d-c9b99e98f88f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f75457c-6f03-4e59-886d-c9b99e98f88f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sections of config\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 200\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 4\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 1e-05\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "NU5z9n3hdshP"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# Uncomment to download \"stopwords\"\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def text_preprocessing(s):\n",
        "    \"\"\"\n",
        "    - Lowercase the sentence\n",
        "    - Change \"'t\" to \"not\"\n",
        "    - Remove \"@name\"\n",
        "    - Isolate and remove punctuations except \"?\"\n",
        "    - Remove other special characters\n",
        "    - Remove stop words except \"not\" and \"can\"\n",
        "    - Remove trailing whitespace\n",
        "    \"\"\"\n",
        "    s = s.lower()\n",
        "    # Change 't to 'not'\n",
        "    s = re.sub(r\"\\'t\", \" not\", s)\n",
        "    # Remove @name\n",
        "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
        "    # Isolate and remove punctuations except '?'\n",
        "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r'  ', s)\n",
        "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
        "    # Remove some special characters\n",
        "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
        "    # Remove stopwords except 'not' and 'can'\n",
        "    s = \" \".join([word for word in s.split()\n",
        "                  if word not in stopwords.words('english')\n",
        "                  or word in ['not', 'can']])\n",
        "    # Remove trailing whitespace\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "\n",
        "    return s"
      ],
      "metadata": {
        "id": "VBBTWdrysgg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d91b9366-d6f0-4106-f60c-0b376d79955e"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.comment_text = dataframe.Text\n",
        "        self.targets = self.data.One\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        comment_text = str(self.comment_text[index])\n",
        "        comment_text = \" \".join(comment_text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text_preprocessing(comment_text),\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ],
      "metadata": {
        "id": "iNy37lmWpo3G"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset=new_df.sample(frac=train_size,random_state=200)\n",
        "test_dataset=new_df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioj1na9LqhJZ",
        "outputId": "8c1dd030-dda2-410e-b426-7e821caf1904"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (20000, 2)\n",
            "TRAIN Dataset: (16000, 2)\n",
            "TEST Dataset: (4000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "qvhYma_4qnUu"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
        "\n",
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(768, 5)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
        "        output_2 = self.l2(output_1)\n",
        "        output = self.l3(output_2)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR0sZ8_AqrJj",
        "outputId": "26f4a668-8ff9-4e62-afca-bc1db6981e9e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Dropout(p=0.3, inplace=False)\n",
              "  (l3): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ],
      "metadata": {
        "id": "i6yrcrAOqzJu"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "YwnDJzipqzGY"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _%5000==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        ""
      ],
      "metadata": {
        "id": "FYgrLLARqzDY"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i812PW32qzAP",
        "outputId": "184662dc-ebac-4d92-b64f-b30837726456"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  0.7352115511894226\n",
            "Epoch: 1, Loss:  0.2800705134868622\n",
            "Epoch: 2, Loss:  0.1666410118341446\n",
            "Epoch: 3, Loss:  0.03641340136528015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(epoch):\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "metadata": {
        "id": "9Zfw8x4a2TQV"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1):\n",
        "    outputs, targets = validation(epoch)\n",
        "    outputs = np.array(outputs) >= np.max(outputs, axis=1, keepdims=True)\n",
        "    accuracy = metrics.accuracy_score(targets, outputs)\n",
        "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbj0JSId2Ypn",
        "outputId": "62d5605f-e81d-44a8-bd1d-c4a0bea30664"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score = 0.72425\n",
            "F1 Score (Micro) = 0.72425\n",
            "F1 Score (Macro) = 0.5313328590212294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text1=test_dataset[:1]['Text']\n",
        "text1=test_dataset.loc[0, 'Text']"
      ],
      "metadata": {
        "id": "UrycMPqzEuKO"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=text1\n",
        "inputs = tokenizer.encode_plus(\n",
        "            text_preprocessing(text),\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=MAX_LEN,\n",
        "            padding=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "ids = inputs['input_ids']\n",
        "mask = inputs['attention_mask']\n",
        "token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paIAB8Lj-sMe",
        "outputId": "0aa7e618-c2cb-43f8-c471-b72b49e71737"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2632: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch.nn as nn\n",
        "\n",
        "# Assuming data is a dictionary with 'ids', 'mask', and 'token_type_ids' as keys\n",
        "data = {\n",
        "    'ids': ids,               # Replace with your actual data\n",
        "    'mask': mask,              # Replace with your actual data\n",
        "    'token_type_ids': token_type_ids     # Replace with your actual data\n",
        "}\n",
        "\n",
        "# Convert lists to PyTorch tensors\n",
        "ids = torch.tensor(data['ids'], dtype=torch.long).unsqueeze(0)  # Add an extra dimension for batch\n",
        "mask = torch.tensor(data['mask'], dtype=torch.long).unsqueeze(0)  # Add an extra dimension for batch\n",
        "token_type_ids = torch.tensor(data['token_type_ids'], dtype=torch.long).unsqueeze(0)  # Add an extra dimension for batch\n",
        "\n",
        "# Move tensors to the desired device (e.g., GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "token_type_ids = token_type_ids.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Pass the input through the model to get the output\n",
        "outputs = model(ids,mask,token_type_ids)\n",
        "\n",
        "# Now 'outputs' contains the model's prediction\n"
      ],
      "metadata": {
        "id": "NFoAOuBaD3xq"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=torch.sigmoid(outputs).cpu().detach().numpy().tolist()\n",
        "index_of_max = np.argmax(output)\n",
        "print(index_of_max + 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvY3N410-S1X",
        "outputId": "5305cdae-e34e-4a00-d914-81967dc3bab5"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, '/content/drive/MyDrive/AI_models/Bert_finetune_on_Amazon_reviews')"
      ],
      "metadata": {
        "id": "P0LOkje_NZoS"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save only the model parameters\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/AI_models/Bert_finetune_on_Amazon_reviews_state_dict.pth')"
      ],
      "metadata": {
        "id": "Ux_pcIjzQisX"
      },
      "execution_count": 125,
      "outputs": []
    }
  ]
}